# Example Usage and Configuration

This document provides practical examples and common configuration scenarios for the Imagines Nummorum VLM Data Extraction pipeline.

## Basic Configuration Examples

### 1. Minimal Configuration for Testing

```python
# Configuration for quick testing with a small dataset
INPUT_IMAGE_DIRECTORY = "./test_images"
OUTPUT_JSON_DIRECTORY = "./test_output"
MODEL_ID = "Qwen/Qwen2.5-VL-7B-Instruct"  # Smaller model for testing
MODEL_CACHE_DIR = "./model_cache"
OCR_STRATEGY_FOR_TEXT_PAGES = "qwen_text_only"
MAX_JSON_RETRIES = 2
```

### 2. Production Configuration

```python
# Configuration for large-scale processing
INPUT_IMAGE_DIRECTORY = "/data/coin_collections/batch_2025"
OUTPUT_JSON_DIRECTORY = "/results/processed_2025"
MODEL_ID = "Qwen/Qwen2.5-VL-32B-Instruct"  # Full model for best results
MODEL_CACHE_DIR = "/models/cache"
OCR_STRATEGY_FOR_TEXT_PAGES = "both"  # Maximum accuracy
MAX_JSON_RETRIES = 3
OVERWRITE_EXISTING_OUTPUT = False  # Don't reprocess existing files
```

### 3. Memory-Constrained Environment

```python
# Configuration for systems with limited RAM
INPUT_IMAGE_DIRECTORY = "./input"
OUTPUT_JSON_DIRECTORY = "./output"
MODEL_ID = "Qwen/Qwen2.5-VL-7B-Instruct"  # Smaller model
MODEL_CACHE_DIR = "./cache"
OCR_STRATEGY_FOR_TEXT_PAGES = "tesseract_hocr_only"  # Lower memory usage
CROP_MARGIN_PIXELS = 30  # Smaller crops to save memory
DEBUG_VISUALIZATION = False  # Disable debug images
```

### 4. Configuration with Explicit Tesseract Path

```python
# Configuration when Tesseract is not in system PATH
import pytesseract

# Windows example
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Linux example  
# pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

# macOS example
# pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'

INPUT_IMAGE_DIRECTORY = "./input_images"
OUTPUT_JSON_DIRECTORY = "./output_results"
OCR_STRATEGY_FOR_TEXT_PAGES = "both"  # Use both Tesseract and Qwen
```

### 5. Jupyter Notebook Configuration

```python
# Configuration optimized for Jupyter environments
import sys
import os

# Add project root to path if needed
sys.path.append('/path/to/project/root')

# Configuration
INPUT_IMAGE_DIRECTORY = "./sample_data"
OUTPUT_JSON_DIRECTORY = "./notebook_results"
MODEL_ID = "Qwen/Qwen2.5-VL-7B-Instruct"  # Smaller model for notebooks
MODEL_CACHE_DIR = "./models"

# Enable progress bars in Jupyter
from tqdm.notebook import tqdm

# Execute processing
exec(open('src/coin_card_information_extraction.py').read())
```

## Example Processing Workflows

### Workflow 1: Museum Catalog Digitization

**Scenario**: Processing scanned museum catalog cards with coin images

```python
# 1. Organize input directory
input_structure = """
museum_catalog/
├── collection_ancient_greek/
│   ├── athens_tetradrachm_001.jpg
│   ├── athens_tetradrachm_002.jpg
│   └── corinth_stater_001.jpg
├── collection_roman/
│   ├── augustus_denarius_001.jpg
│   └── trajan_sestertius_001.jpg
└── documentation_pages/
    ├── catalog_page_001.jpg
    └── notes_page_001.jpg
"""

# 2. Configuration
CONFIG = {
    "INPUT_IMAGE_DIRECTORY": "./museum_catalog",
    "OUTPUT_JSON_DIRECTORY": "./catalog_results",
    "MODEL_ID": "Qwen/Qwen2.5-VL-32B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "both",
    "CROP_MARGIN_PIXELS": 50  # Larger margin for museum quality
}

# 3. Expected output structure
output_structure = """
catalog_results/
├── collection_ancient_greek/
│   ├── athens_tetradrachm_001.json
│   ├── athens_tetradrachm_001_extracted_images/
│   │   ├── athens_tetradrachm_001_1.png
│   │   └── athens_tetradrachm_001_2.png
│   └── ...
├── collection_roman/
│   └── ...
└── coin_data.csv  # Generated by json_to_csv.py
"""
```

### Workflow 2: Archaeological Documentation

**Scenario**: Processing field documentation with embedded photos

```python
# Configuration optimized for archaeological field photos
CONFIG = {
    "INPUT_IMAGE_DIRECTORY": "./field_documentation",
    "OUTPUT_JSON_DIRECTORY": "./archaeological_results",
    "MODEL_ID": "Qwen/Qwen2.5-VL-32B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "qwen_then_tesseract_fallback",
    "CROP_MARGIN_PIXELS": 60,  # Larger margin for field photos
    "COLOR_SIMILARITY_THRESHOLD": 40,  # More tolerance for varied lighting
    "EDGE_UNIFORMITY_THRESHOLD": 0.75  # Lower threshold for non-studio photos
}

# Processing script
def process_archaeological_batch():
    # 1. Pre-filter images by date
    recent_images = filter_images_by_date("./field_documentation", days=30)

    # 2. Process in daily batches
    for date, images in group_by_date(recent_images):
        print(f"Processing {len(images)} images from {date}")
        batch_process_images_multi_stage(
            input_dir=f"./field_documentation/{date}",
            output_dir=f"./archaeological_results/{date}",
            **CONFIG
        )

        # 3. Generate daily report
        generate_daily_report(f"./archaeological_results/{date}")
```

### Workflow 3: Digital Archive Processing

**Scenario**: Large-scale digitization of historical archives

```python
# Configuration for high-volume processing
CONFIG = {
    "INPUT_IMAGE_DIRECTORY": "/archive/historical_collections",
    "OUTPUT_JSON_DIRECTORY": "/processed/archive_results",
    "MODEL_ID": "Qwen/Qwen2.5-VL-32B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "both",
    "MAX_JSON_RETRIES": 5,  # Higher retries for valuable content
    "OVERWRITE_EXISTING_OUTPUT": False  # Resume capability
}

# Chunked processing for large archives
def process_archive_in_chunks(chunk_size=1000):
    all_images = find_all_images(CONFIG["INPUT_IMAGE_DIRECTORY"])

    for i, chunk in enumerate(chunks(all_images, chunk_size)):
        print(f"Processing chunk {i+1}: {len(chunk)} images")

        # Process chunk
        results = []
        for image_path in tqdm(chunk, desc=f"Chunk {i+1}"):
            result = process_single_image_multi_stage(
                image_path,
                CONFIG["OUTPUT_JSON_DIRECTORY"],
                model, processor, device,
                CONFIG["INPUT_IMAGE_DIRECTORY"]
            )
            results.append(result)

        # Save chunk summary
        save_chunk_summary(i+1, results)

        # Memory cleanup
        cleanup_memory()

        # Progress checkpoint
        save_processing_checkpoint(i+1, len(chunks))
```

## Sample Input and Output Examples

### Example 1: Coin Catalog Card

**Input**: Museum catalog card with coin photos and metadata

**Expected JSON Output**:

```json
{
  "image_path_original": "/museum_catalog/athens_tetradrachm_001.jpg",
  "image_type": "form",
  "handwritten_content": true,
  "data": {
    "form_data": {
      "coins": [
        {
          "id": "coin_1",
          "description": "Athenian silver tetradrachm, owl reverse, Athena obverse",
          "bounding_box": {
            "x": 150,
            "y": 200,
            "width": 180,
            "height": 180
          }
        }
      ],
      "card_fields": {
        "Atelier": "Athens",
        "Date": "440-430 BC",
        "Métal": "Silver",
        "Poids": "17.2g",
        "Diamètre": "24mm",
        "Orientation des axes": "12h",
        "Technique": "Struck",
        "Publication": "Svoronos 1904, pl. 12.3",
        "Négatifs": "N12345",
        "Remarques": "Excellent preservation, minor edge wear"
      }
    }
  },
  "images_extracted": [
    "athens_tetradrachm_001_extracted_images/athens_tetradrachm_001_1.png"
  ],
  "status": "success",
  "error_message": null
}
```

### Example 2: Text Page

**Input**: Historical manuscript or printed catalog page

**Expected JSON Output**:

```json
{
  "image_path_original": "/documentation/catalog_page_001.jpg",
  "image_type": "text_page",
  "handwritten_content": false,
  "data": {
    "ocr_results": [
      {
        "source": "tesseract",
        "type": "hocr",
        "content": "<?xml version='1.0' encoding='UTF-8'?><!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN' 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'><html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>...</html>",
        "status": "success",
        "error_message": null
      },
      {
        "source": "qwen_vl",
        "type": "plain_text",
        "content": "CATALOG OF ANCIENT COINS\n\nCollection: Athenian Tetradrachms\nPeriod: 5th-4th Century BC\n\nItem 1: Silver Tetradrachm\nMint: Athens\nDate: c. 440-430 BC\nWeight: 17.2g\nDiameter: 24mm\n\nObverse: Head of Athena right, wearing crested helmet\nReverse: Owl standing right, olive sprig and crescent\nReference: Svoronos 1904, Type IV\n\nCondition: Very Fine\nProvenance: Ex. Collection Dr. Smith, acquired 1987",
        "status": "success",
        "error_message": null
      }
    ]
  },
  "images_extracted": [],
  "status": "success",
  "error_message": null
}
```

## Common Configuration Scenarios

### High Accuracy Setup (Research Quality)

```python
# Maximum quality configuration
RESEARCH_CONFIG = {
    "MODEL_ID": "Qwen/Qwen2.5-VL-32B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "both",
    "MAX_JSON_RETRIES": 5,
    "RETRY_DELAY_SECONDS": 2,
    "CROP_MARGIN_PIXELS": 60,
    "INITIAL_CROP_MARGIN": 30,
    "MAX_CROP_MARGIN": 150,
    "MARGIN_INCREMENT": 3,
    "COLOR_SIMILARITY_THRESHOLD": 25,
    "EDGE_UNIFORMITY_THRESHOLD": 0.90,
    "DEBUG_VISUALIZATION": True
}
```

### Speed Optimized Setup

```python
# Fast processing configuration
SPEED_CONFIG = {
    "MODEL_ID": "Qwen/Qwen2.5-VL-7B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "qwen_text_only",
    "MAX_JSON_RETRIES": 2,
    "RETRY_DELAY_SECONDS": 0.5,
    "CROP_MARGIN_PIXELS": 40,
    "INITIAL_CROP_MARGIN": 20,
    "MAX_CROP_MARGIN": 80,
    "MARGIN_INCREMENT": 10,
    "DEBUG_VISUALIZATION": False
}
```

### Robust/Fault-Tolerant Setup

```python
# Configuration for unreliable processing conditions
ROBUST_CONFIG = {
    "MODEL_ID": "Qwen/Qwen2.5-VL-32B-Instruct",
    "OCR_STRATEGY_FOR_TEXT_PAGES": "tesseract_then_qwen_fallback",
    "MAX_JSON_RETRIES": 10,
    "RETRY_DELAY_SECONDS": 3,
    "OVERWRITE_EXISTING_OUTPUT": False,  # Resume on failure
    "CROP_MARGIN_PIXELS": 50,
    "COLOR_SIMILARITY_THRESHOLD": 35,
    "EDGE_UNIFORMITY_THRESHOLD": 0.80
}
```

## Integration Examples

### Database Integration

```python
# Example: Export to PostgreSQL database
import pandas as pd
import psycopg2
from sqlalchemy import create_engine

def export_to_database():
    # 1. Convert JSON to CSV
    df = pd.read_csv('coin_data.csv')

    # 2. Connect to database
    engine = create_engine('postgresql://user:password@localhost/numismatic_db')

    # 3. Create tables and export
    df.to_sql('coin_records', engine, if_exists='append', index=False)

    print(f"Exported {len(df)} records to database")

# Example: Custom field mapping
def map_fields_for_database(df):
    field_mapping = {
        'card_Atelier': 'mint_name',
        'card_Date': 'dating',
        'card_Métal': 'metal_composition',
        'card_Poids': 'weight_grams',
        'card_Diamètre': 'diameter_mm'
    }

    return df.rename(columns=field_mapping)
```

### Web Interface Integration

```python
# Example: Simple Flask web interface
from flask import Flask, render_template, jsonify, request
import json
import os

app = Flask(__name__)

@app.route('/')
def index():
    return render_template('viewer.html')

@app.route('/api/results')
def get_results():
    results = []
    output_dir = './output_results'

    for root, dirs, files in os.walk(output_dir):
        for file in files:
            if file.endswith('.json'):
                with open(os.path.join(root, file)) as f:
                    data = json.load(f)
                    results.append(data)

    return jsonify(results)

@app.route('/api/search')
def search_results():
    query = request.args.get('q', '')
    # Implement search logic
    return jsonify(filtered_results)

if __name__ == '__main__':
    app.run(debug=True)
```

### Automated Processing Pipeline

```python
# Example: Automated processing with file monitoring
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ImageProcessor(FileSystemEventHandler):
    def on_created(self, event):
        if event.is_dir:
            return

        # Check if it's an image file
        if event.src_path.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff')):
            print(f"New image detected: {event.src_path}")

            # Wait for file to be fully written
            time.sleep(2)

            # Process the image
            result = process_single_image_multi_stage(
                event.src_path,
                OUTPUT_JSON_DIRECTORY,
                model, processor, device,
                INPUT_IMAGE_DIRECTORY
            )

            print(f"Processing completed: {result['status']}")

def start_monitoring():
    event_handler = ImageProcessor()
    observer = Observer()
    observer.schedule(event_handler, INPUT_IMAGE_DIRECTORY, recursive=True)
    observer.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()
```

## Performance Tuning Examples

### Memory Usage Optimization

```python
# Monitor and optimize memory usage
import psutil
import gc

def optimize_memory_usage():
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB

    print(f"Initial memory usage: {initial_memory:.1f} MB")

    # Process with periodic cleanup
    for i, image_path in enumerate(image_paths):
        result = process_single_image(image_path)

        # Cleanup every 10 images
        if i % 10 == 0:
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            current_memory = process.memory_info().rss / 1024 / 1024
            print(f"Memory after {i} images: {current_memory:.1f} MB")

            # If memory usage is too high, pause
            if current_memory > initial_memory * 2:
                print("High memory usage detected, pausing...")
                time.sleep(5)
                gc.collect()
```

### Parallel Processing Example

```python
# Process multiple images in parallel (CPU-bound operations)
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import multiprocessing

def parallel_image_processing(image_paths, max_workers=None):
    if max_workers is None:
        max_workers = min(multiprocessing.cpu_count(), 4)

    # For I/O-bound operations (file reading, OCR)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        ocr_results = list(executor.map(process_ocr_only, image_paths))

    # For CPU-bound operations (image processing)
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        processing_results = list(executor.map(process_image_analysis, image_paths))

    return combine_results(ocr_results, processing_results)
```

This examples file provides practical guidance for users to implement the system in various real-world scenarios, from simple testing to complex production environments.
